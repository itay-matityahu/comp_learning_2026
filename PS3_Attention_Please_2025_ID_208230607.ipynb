{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOpGoE2T-YXS"
      },
      "source": [
        "# Neural Machine Translation with Attention\n",
        "\n",
        "Advanced Learning Fall 2025\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For SUBMISSION:   \n",
        "\n",
        "Please upload the complete and executed `ipynb` to your git repository. Verify that all of your output can be viewed directly from github, and provide a link to that git file below.\n",
        "\n",
        "~~~\n",
        "STUDENT ID: 208230607\n",
        "~~~\n",
        "\n",
        "~~~\n",
        "STUDENT GIT LINK: https://github.com/itay-matityahu/comp_learning_2026\n",
        "~~~\n",
        "In Addition, don't forget to add your ID to the files, and upload to moodle the html version:    \n",
        "  \n",
        "`PS3_Attention_2025_ID_[000000000].html`   \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PpJdYve9cZa6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eecp2PAf7qJq"
      },
      "source": [
        "In this problem set we are going to jump into the depths of `seq2seq` and `attention` and build a couple of PyTorch translation mechanisms with some  twists.     \n",
        "\n",
        "\n",
        "*   Part 1 consists of a somewhat unorthodox `seq2seq` model for simple arithmetics\n",
        "*   Part 2 consists of an `seq2seq - attention` language translation model. We will use it for Hebrew and English.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "-VpUCez9gOZn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajNDsL5HlZN6"
      },
      "source": [
        "A **seq2seq** model (sequence-to-sequence model) is a type of neural network designed specifically to handle sequences of data. The model converts input sequences into other sequences of data. This makes them particularly useful for tasks involving language, where the input and output are naturally sequences of words.\n",
        "\n",
        "Here's a breakdown of how `seq2seq` models work:\n",
        "\n",
        "* The encoder takes the input sequence, like a sentence in English, and processes it to capture its meaning and context.\n",
        "\n",
        "* information is then passed to the decoder, which uses it to generate the output sequence, like a translation in French.\n",
        "\n",
        "* Attention mechanism (optional): Some `seq2seq` models also incorporate an attention mechanism. This allows the decoder to focus on specific parts of the input sequence that are most relevant to generating the next element in the output sequence.\n",
        "\n",
        "`seq2seq` models are used in many natural language processing (NLP) tasks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbUDn4FObol7"
      },
      "source": [
        "imports: (feel free to add)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "crTe33wcD_Eg"
      },
      "outputs": [],
      "source": [
        "# from __future__ import unicode_literals, print_function, division\n",
        "# from io import open\n",
        "# import unicodedata\n",
        "import re\n",
        "import random\n",
        "import unicodedata\n",
        "\n",
        "import time\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiwtNgENbx2g"
      },
      "source": [
        "## Part 1: Seq2Seq Arithmetic model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1gWov3Gx67I"
      },
      "source": [
        "**Using RNN `seq2seq` model to \"learn\" simple arithmetics!**\n",
        "\n",
        "> Given the string \"54-7\", the model should return a prediction: \"47\".  \n",
        "> Given the string \"10+20\", the model should return a prediction: \"30\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dxo92ZgTy6ED"
      },
      "source": [
        "- Watch Lukas Biewald's short [video](https://youtu.be/MqugtGD605k?si=rAH34ZTJyYDj-XJ1) explaining `seq2seq` models and his toy application (somewhat outdated).\n",
        "- You can find the code for his example [here](https://github.com/lukas/ml-class/blob/master/videos/seq2seq/train.py).    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEu_5YvqFPai"
      },
      "source": [
        "1.1) Using Lukas' code, implement a `seq2seq` network that can learn how to solve **addition AND substraction** of two numbers of maximum length of 4, using the following steps (similar to the example):      \n",
        "\n",
        "* Generate data; X: queries (two numbers), and Y: answers   \n",
        "* One-hot encode X and Y,\n",
        "* Build a `seq2seq` network (with LSTM, RepeatVector, and TimeDistributed layers)\n",
        "* Train the model.\n",
        "* While training, sample from the validation set at random so we can visualize the generated solutions against the true solutions.    \n",
        "\n",
        "Notes:  \n",
        "* The code in the example is quite old and based on Keras. You might have to adapt some of the code to overcome methods/code that is not supported anymore. Hint: for the evaluation part, review the type and format of the \"correct\" output - this will help you fix the unsupported \"model.predict_classes\".\n",
        "* Please use the parameters in the code cell below to train the model.     \n",
        "* Instead of using a `wandb.config` object, please use a simple dictionary instead.   \n",
        "* You don't need to run the model for more than 50 iterations (epochs) to get a gist of what is happening and what the algorithm is doing.\n",
        "* Extra credit if you can implement the network in PyTorch (this is not difficult).    \n",
        "* Extra credit if you are able to significantly improve the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bwZKyzoBKl4G"
      },
      "outputs": [],
      "source": [
        "config = {}\n",
        "config[\"training_size\"] = 40000\n",
        "config[\"digits\"] = 4\n",
        "config[\"hidden_size\"] = 128\n",
        "config[\"batch_size\"] = 128\n",
        "config[\"iterations\"] = 50\n",
        "chars = '0123456789-+ '"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1"
      ],
      "metadata": {
        "id": "KC9v9TOPtsIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CharacterTable(object):\n",
        "    \"\"\"Given a set of characters:\n",
        "    + Encode them to a one hot integer representation\n",
        "    + Decode the one hot integer representation to their character output\n",
        "    + Decode a vector of probabilities to their character output\n",
        "    \"\"\"\n",
        "    def __init__(self, chars):\n",
        "        \"\"\"Initialize character table.\n",
        "        # Arguments\n",
        "            chars: Characters that can appear in the input.\n",
        "        \"\"\"\n",
        "        self.chars = sorted(set(chars))\n",
        "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
        "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
        "\n",
        "    def encode(self, C, num_rows):\n",
        "        \"\"\"One hot encode given string C.\n",
        "        # Arguments\n",
        "            num_rows: Number of rows in the returned one hot encoding. This is\n",
        "                used to keep the # of rows for each data the same.\n",
        "        \"\"\"\n",
        "        x = np.zeros((num_rows, len(self.chars)))\n",
        "        for i, c in enumerate(C):\n",
        "            x[i, self.char_indices[c]] = 1\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, calc_argmax=True):\n",
        "        if calc_argmax:\n",
        "            x = x.argmax(axis=-1)\n",
        "        return ''.join(self.indices_char[x] for x in x)\n",
        "\n",
        "class Seq2SeqArithmetic(nn.Module):\n",
        "    def __init__(self, input_vocab_size, hidden_size, output_vocab_size, output_len):\n",
        "        super(Seq2SeqArithmetic, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_len = output_len\n",
        "\n",
        "        # --- Encoder ---\n",
        "        # input_vocab_size is len(chars)\n",
        "        self.encoder_lstm = nn.LSTM(input_size=input_vocab_size,\n",
        "                                    hidden_size=hidden_size,\n",
        "                                    batch_first=True)\n",
        "\n",
        "        # --- Decoder ---\n",
        "        # The decoder LSTM takes the \"Context Vector\" as input at every step\n",
        "        self.decoder_lstm = nn.LSTM(input_size=hidden_size,\n",
        "                                    hidden_size=hidden_size,\n",
        "                                    batch_first=True)\n",
        "\n",
        "        # TimeDistributed Dense (Linear layer in PyTorch)\n",
        "        self.fc = nn.Linear(hidden_size, output_vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 1. Encoder: process the whole input sequence\n",
        "        # We only care about the final hidden state (the context vector)\n",
        "        _, (h_n, c_n) = self.encoder_lstm(x)\n",
        "\n",
        "        # 2. \"RepeatVector\": Repeat h_n to match output_len\n",
        "        # h_n shape: (1, batch, hidden) -> permute to (batch, 1, hidden)\n",
        "        context_vector = h_n.permute(1, 0, 2)\n",
        "        # Repeat it for the length of the answer (digits + 1)\n",
        "        decoder_input = context_vector.repeat(1, self.output_len, 1)\n",
        "\n",
        "        # 3. Decoder: unpack the context vector into a sequence\n",
        "        # We use the final encoder states (h_n, c_n) to initialize the decoder\n",
        "        decoder_output, _ = self.decoder_lstm(decoder_input, (h_n, c_n))\n",
        "\n",
        "        # 4. \"TimeDistributed\": apply Linear layer to every time step\n",
        "        prediction = self.fc(decoder_output)\n",
        "\n",
        "        return prediction\n"
      ],
      "metadata": {
        "id": "eKJc4re1RY-1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "maxlen = config['digits'] + 1 + config['digits']\n",
        "ctable = CharacterTable(chars)\n",
        "\n",
        "questions = []\n",
        "expected = []\n",
        "seen = set()\n",
        "print('Generating data...')\n",
        "while len(questions) < config[\"training_size\"]:\n",
        "    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
        "                    for i in range(np.random.randint(1, config['digits'] + 1))))\n",
        "    a, b = f(), f()\n",
        "    # Skip any addition questions we've already seen\n",
        "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
        "    key = tuple(sorted((a, b)))\n",
        "    if key in seen:\n",
        "        continue\n",
        "    seen.add(key)\n",
        "    # Pad the data with spaces such that it is always MAXLEN.\n",
        "    q = '{}-{}'.format(a, b)\n",
        "    query = q + ' ' * (maxlen - len(q))\n",
        "    ans = str(a - b)\n",
        "    # Answers can be of maximum size DIGITS + 1.\n",
        "    ans += ' ' * (config['digits'] + 1 - len(ans))\n",
        "\n",
        "    questions.append(query)\n",
        "    expected.append(ans)\n",
        "\n",
        "print('Total addition questions:', len(questions))\n",
        "\n",
        "\n",
        "x = np.zeros((len(questions), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(questions), config['digits'] + 1, len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(questions):\n",
        "  x[i] = ctable.encode(sentence, maxlen)\n",
        "for i, sentence in enumerate(expected):\n",
        "  y[i] = ctable.encode(sentence, config['digits'] + 1)\n",
        "\n",
        "indices = np.arange(len(y))\n",
        "np.random.shuffle(indices)\n",
        "x = x[indices]\n",
        "y = y[indices]\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.1, random_state=42)\n",
        "\n",
        "x_train_tensor = torch.from_numpy(x_train).float()\n",
        "y_train_tensor = torch.from_numpy(y_train).float()\n",
        "\n",
        "x_val_tensor = torch.from_numpy(x_val).float()\n",
        "y_val_tensor = torch.from_numpy(y_val).float()\n",
        "\n",
        "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92DIH86ARUMn",
        "outputId": "9eac9dc1-9af0-498a-9545-08911183c77a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating data...\n",
            "Total addition questions: 40000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Seq2SeqArithmetic(\n",
        "    input_vocab_size=len(chars),\n",
        "    hidden_size=config[\"hidden_size\"],\n",
        "    output_vocab_size=len(chars),\n",
        "    output_len=config[\"digits\"] + 1\n",
        ").to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(config[\"iterations\"]):\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "\n",
        "  for i, (x_batch, y_batch) in enumerate(train_loader):\n",
        "    x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "    pred = model(x_batch)\n",
        "\n",
        "    flat_pred = pred.view(-1, len(chars))\n",
        "    flat_real = torch.argmax(y_batch, dim=-1).view(-1)\n",
        "\n",
        "    loss = criterion(flat_pred, flat_real)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "  model.eval()\n",
        "  char_acc = 0\n",
        "  seq_acc = 0\n",
        "  total_samples = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for x_val, y_val in val_loader:\n",
        "      x_val, y_val = x_val.to(device), y_val.to(device)\n",
        "\n",
        "      outputs = model(x_val)\n",
        "\n",
        "      pred_indices = torch.argmax(outputs, dim=-1)\n",
        "      target_indices = torch.argmax(y_val, dim=-1)\n",
        "      correct_matrix = (pred_indices == target_indices)\n",
        "\n",
        "      char_acc += correct_matrix.sum().item()\n",
        "      seq_acc += (correct_matrix.all(dim=1)).sum().item()\n",
        "      total_samples += x_val.size(0)\n",
        "    total_chars = total_samples * (config[\"digits\"] + 1)\n",
        "  if (epoch+1) % 5 == 0:\n",
        "    print(f\"Epoch {epoch+1}/{config['iterations']}, Loss: {total_loss/len(train_loader):.4f}\")\n",
        "    print(f\"Character Accuracy: {char_acc / total_chars:.4f}\")\n",
        "    print(f\"Full Equation Accuracy: {seq_acc / total_samples:.4f}\")\n",
        "\n",
        "for i in range(5):\n",
        "    idx = random.randint(0, x_val.size(0) - 1)\n",
        "    q = ctable.decode(x_val[idx].cpu().numpy())\n",
        "    expected = ctable.decode(y_val[idx].cpu().numpy())\n",
        "    predicted = ctable.decode(pred_indices[idx].cpu().numpy(), calc_argmax=False)\n",
        "    print(f\"Q: {q} | Expected: {expected} | Predicted: {predicted}\")\n"
      ],
      "metadata": {
        "id": "GlF7abtLjz06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e85956dc-2ddb-4982-bf3e-84b9a72b5c17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/50, Loss: 1.5110\n",
            "Character Accuracy: 0.4294\n",
            "Full Equation Accuracy: 0.0025\n",
            "Epoch 10/50, Loss: 1.2587\n",
            "Character Accuracy: 0.5118\n",
            "Full Equation Accuracy: 0.0088\n",
            "Epoch 15/50, Loss: 1.0782\n",
            "Character Accuracy: 0.5857\n",
            "Full Equation Accuracy: 0.0217\n",
            "Epoch 20/50, Loss: 0.9619\n",
            "Character Accuracy: 0.6371\n",
            "Full Equation Accuracy: 0.0423\n",
            "Epoch 25/50, Loss: 0.8663\n",
            "Character Accuracy: 0.6645\n",
            "Full Equation Accuracy: 0.0650\n",
            "Epoch 30/50, Loss: 0.7850\n",
            "Character Accuracy: 0.6872\n",
            "Full Equation Accuracy: 0.1027\n",
            "Epoch 35/50, Loss: 0.7134\n",
            "Character Accuracy: 0.7134\n",
            "Full Equation Accuracy: 0.1400\n",
            "Epoch 40/50, Loss: 0.6467\n",
            "Character Accuracy: 0.7274\n",
            "Full Equation Accuracy: 0.1840\n",
            "Epoch 45/50, Loss: 0.5770\n",
            "Character Accuracy: 0.7531\n",
            "Full Equation Accuracy: 0.2340\n",
            "Epoch 50/50, Loss: 0.5116\n",
            "Character Accuracy: 0.7623\n",
            "Full Equation Accuracy: 0.2722\n",
            "Q: 44-8513   | Expected: -8469 | Predicted: -8478\n",
            "Q: 8811-86   | Expected: 8725  | Predicted: 8742 \n",
            "Q: 61-1419   | Expected: -1358 | Predicted: -1358\n",
            "Q: 496-5     | Expected: 491   | Predicted: 491  \n",
            "Q: 8-2266    | Expected: -2258 | Predicted: -2258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "voVYROYNlO49"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2"
      ],
      "metadata": {
        "id": "94tZgheCwWD1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXJQqZbEbRup"
      },
      "source": [
        "1.2).\n",
        "\n",
        "a) Do you think this model performs well?  Why or why not?     \n",
        "b) What are its limitations?   \n",
        "c) What would you do to improve it?    \n",
        "d) Can you apply an attention mechanism to this model? Why or why not?   "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. The model got accuracy of 76% accuracy when examine character accuracy which is nice, but when looking on solution accuracy we can see that only 27% of the model answers are true and therefore the model has a lot to improve.\n",
        "Anyway, it still has better performance than lukas model (69%).\n",
        "\n",
        "b. As mentioned before, The model has nice accuracy when trying to predict one number, but for solving larger problems the probabily to success decreased significantly (0.76^n). It is the major limit of the model.\n",
        "\n",
        "c. The model can be improved using more lstm layers / Bilstm / attention or any architecture that may improve the memory and context of the previous charactars. It also can be improved by teacher forcing.\n",
        "\n",
        "d. Yes, attention can be added to this model and may be very helpfull when dealing with data like this since there is true connection between the characters, and attention can capture it."
      ],
      "metadata": {
        "id": "liC5ScVAt0t3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3"
      ],
      "metadata": {
        "id": "4l9pQJoswao9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.3).  \n",
        "\n",
        "Add attention to the model. Evaluate the performance against the `seq2seq` you trained above. Which one is performing better?\n",
        "\n",
        "The model with the attention addition has very similar performance but a littelt bit lower that the first one in surprisingly way."
      ],
      "metadata": {
        "id": "6wvRhhOcgmrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. THE ATTENTION MECHANISM\n",
        "# Calculates which part of the input sequence to focus on\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(Attention, self).__init__()\n",
        "        self.attn = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.v = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        # hidden: [1, batch, hidden_size] | encoder_outputs: [batch, seq_len, hidden_size]\n",
        "        src_len = encoder_outputs.shape[1]\n",
        "\n",
        "        # Repeat hidden state for every time-step in encoder_outputs\n",
        "        hidden = hidden.transpose(0, 1).repeat(1, src_len, 1)\n",
        "\n",
        "        # Calculate scores\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "        attention = self.v(energy).squeeze(2)\n",
        "\n",
        "        return F.softmax(attention, dim=1)\n",
        "\n",
        "# 2. THE ENCODER\n",
        "# Processes the question and returns ALL hidden states\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_size, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs, (hidden, cell) = self.lstm(x)\n",
        "        return outputs, hidden, cell\n",
        "\n",
        "# 3. THE DECODER\n",
        "# Predicts one character at a time using attention\n",
        "class DecoderWithAttention(nn.Module):\n",
        "    def __init__(self, output_dim, hidden_size, attention):\n",
        "        super(DecoderWithAttention, self).__init__()\n",
        "        self.attention = attention\n",
        "        self.lstm = nn.LSTM(hidden_size + output_dim, hidden_size, batch_first=True)\n",
        "        self.fc_out = nn.Linear(hidden_size * 2, output_dim)\n",
        "\n",
        "    def forward(self, input_char, hidden, cell, encoder_outputs):\n",
        "        # Calculate attention weights and context vector\n",
        "        a = self.attention(hidden, encoder_outputs).unsqueeze(1)\n",
        "        weighted = torch.bmm(a, encoder_outputs) # [batch, 1, hidden]\n",
        "\n",
        "        # Combine input and context for LSTM\n",
        "        input_char = input_char.unsqueeze(1) # [batch, 1, vocab_size]\n",
        "        rnn_input = torch.cat((input_char, weighted), dim=2)\n",
        "\n",
        "        output, (hidden, cell) = self.lstm(rnn_input, (hidden, cell))\n",
        "\n",
        "        # Final prediction by combining LSTM output and context\n",
        "        prediction = self.fc_out(torch.cat((output, weighted), dim=2))\n",
        "        return prediction, hidden, cell\n",
        "\n",
        "# 4. THE MAIN SYSTEM\n",
        "# Orchestrates the encoder and the decoder loop\n",
        "class AttentionSeq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, output_len):\n",
        "        super(AttentionSeq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.output_len = output_len\n",
        "\n",
        "    def forward(self, src):\n",
        "        batch_size = src.shape[0]\n",
        "        vocab_size = self.decoder.fc_out.out_features\n",
        "        outputs = torch.zeros(batch_size, self.output_len, vocab_size).to(src.device)\n",
        "\n",
        "        encoder_outputs, hidden, cell = self.encoder(src)\n",
        "\n",
        "        # Initialize the first input as a zero vector (start of sequence)\n",
        "        input_char = torch.zeros(batch_size, vocab_size).to(src.device)\n",
        "\n",
        "        for t in range(self.output_len):\n",
        "            prediction, hidden, cell = self.decoder(input_char, hidden, cell, encoder_outputs)\n",
        "            outputs[:, t:t+1, :] = prediction\n",
        "\n",
        "            # Use current prediction as the next input\n",
        "            input_char = prediction.squeeze(1)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "# Create the components\n",
        "attn = Attention(config[\"hidden_size\"])\n",
        "enc = Encoder(len(chars), config[\"hidden_size\"])\n",
        "dec = DecoderWithAttention(len(chars), config[\"hidden_size\"], attn)\n",
        "\n",
        "# Initialize the main model\n",
        "model = AttentionSeq2Seq(enc, dec, config[\"digits\"] + 1).to(device)\n",
        "\n",
        "# The rest of your code (Criterion, Optimizer) stays EXACTLY the same!\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "YdFhWNposMke"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(config[\"iterations\"]):\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "\n",
        "  for i, (x_batch, y_batch) in enumerate(train_loader):\n",
        "    x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "    pred = model(x_batch)\n",
        "\n",
        "    flat_pred = pred.view(-1, len(chars))\n",
        "    flat_real = torch.argmax(y_batch, dim=-1).view(-1)\n",
        "\n",
        "    loss = criterion(flat_pred, flat_real)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "  model.eval()\n",
        "  char_acc = 0\n",
        "  seq_acc = 0\n",
        "  total_samples = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for x_val, y_val in val_loader:\n",
        "      x_val, y_val = x_val.to(device), y_val.to(device)\n",
        "\n",
        "      outputs = model(x_val)\n",
        "\n",
        "      pred_indices = torch.argmax(outputs, dim=-1)\n",
        "      target_indices = torch.argmax(y_val, dim=-1)\n",
        "      correct_matrix = (pred_indices == target_indices)\n",
        "\n",
        "      char_acc += correct_matrix.sum().item()\n",
        "      seq_acc += (correct_matrix.all(dim=1)).sum().item()\n",
        "      total_samples += x_val.size(0)\n",
        "    total_chars = total_samples * (config[\"digits\"] + 1)\n",
        "  if (epoch+1) % 5 == 0:\n",
        "    print(f\"Epoch {epoch+1}/{config['iterations']}, Loss: {total_loss/len(train_loader):.4f}\")\n",
        "    print(f\"Character Accuracy: {char_acc / total_chars:.4f}\")\n",
        "    print(f\"Full Equation Accuracy: {seq_acc / total_samples:.4f}\")\n",
        "\n",
        "for i in range(5):\n",
        "    idx = random.randint(0, x_val.size(0) - 1)\n",
        "    q = ctable.decode(x_val[idx].cpu().numpy())\n",
        "    expected = ctable.decode(y_val[idx].cpu().numpy())\n",
        "    predicted = ctable.decode(pred_indices[idx].cpu().numpy(), calc_argmax=False)\n",
        "    print(f\"Q: {q} | Expected: {expected} | Predicted: {predicted}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gafj-4yax6wc",
        "outputId": "65590dbd-7a82-4f99-edc1-a27292c3059c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/50, Loss: 1.4487\n",
            "Character Accuracy: 0.4693\n",
            "Full Equation Accuracy: 0.0060\n",
            "Epoch 10/50, Loss: 1.1863\n",
            "Character Accuracy: 0.5622\n",
            "Full Equation Accuracy: 0.0125\n",
            "Epoch 15/50, Loss: 1.0250\n",
            "Character Accuracy: 0.6107\n",
            "Full Equation Accuracy: 0.0283\n",
            "Epoch 20/50, Loss: 0.9085\n",
            "Character Accuracy: 0.6453\n",
            "Full Equation Accuracy: 0.0590\n",
            "Epoch 25/50, Loss: 0.8297\n",
            "Character Accuracy: 0.6673\n",
            "Full Equation Accuracy: 0.0835\n",
            "Epoch 30/50, Loss: 0.7623\n",
            "Character Accuracy: 0.6924\n",
            "Full Equation Accuracy: 0.1115\n",
            "Epoch 35/50, Loss: 0.7019\n",
            "Character Accuracy: 0.7103\n",
            "Full Equation Accuracy: 0.1405\n",
            "Epoch 40/50, Loss: 0.6490\n",
            "Character Accuracy: 0.7232\n",
            "Full Equation Accuracy: 0.1688\n",
            "Epoch 45/50, Loss: 0.6056\n",
            "Character Accuracy: 0.7237\n",
            "Full Equation Accuracy: 0.1730\n",
            "Epoch 50/50, Loss: 0.5508\n",
            "Character Accuracy: 0.7490\n",
            "Full Equation Accuracy: 0.2380\n",
            "Q: 6-3729    | Expected: -3723 | Predicted: -3723\n",
            "Q: 4646-3    | Expected: 4643  | Predicted: 4652 \n",
            "Q: 5527-3122 | Expected: 2405  | Predicted: 2518 \n",
            "Q: 231-643   | Expected: -412  | Predicted: -419 \n",
            "Q: 2532-26   | Expected: 2506  | Predicted: 2507 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4"
      ],
      "metadata": {
        "id": "CQd9znvjvdxR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.4)\n",
        "\n",
        "Using any neural network architecture of your liking, build  a model with the aim to beat the best performing model in 1.1 or 1.3. Compare your results in a meaningful way, and add a short explanation to why you think/thought your suggested network is better.\n",
        "\n",
        "I  used transformer to this mission and the results was much higher than I expected with full equation accuracy of 99% and 99% accuray for each character. It is indeed much higher than both of the models above. The transformers enable the model to learn deep connection between the characters, nuuch better than lstm and thats why I thugh it will have better results."
      ],
      "metadata": {
        "id": "AtEJK5IZkk8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CharacterTable(object):\n",
        "    def __init__(self, chars):\n",
        "        self.chars = sorted(list(set(chars)))\n",
        "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
        "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
        "\n",
        "    def decode(self, x, calc_argmax=False):\n",
        "        if calc_argmax:\n",
        "            # Only use argmax if the input is One-Hot\n",
        "            x = x.argmax(axis=-1)\n",
        "\n",
        "        # We use 'ind' instead of 'x' to avoid shadowing the input variable\n",
        "        return ''.join(self.indices_char[ind] for ind in x)\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=50):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        # 1. Create a matrix of zeros [max_len, d_model]\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "\n",
        "        # 2. Create a vector representing positions [0, 1, 2, ..., max_len-1]\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "        # 3. Calculate the division term for the sine/cosine functions\n",
        "        # This corresponds to the 10000^(2i/d_model) part\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        # 4. Apply sine to even indices and cosine to odd indices\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        # 5. Add a batch dimension and register as a buffer (stays with the model but not trained)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x is the embedding matrix [Batch, Seq_Len, d_model]\n",
        "        # We add the positional encoding to the embedding\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return x\n",
        "\n",
        "\n",
        "class TransformerInput(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model):\n",
        "        super(TransformerInput, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoding = PositionalEncoding(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x contains the indices of the characters (from CharacterTable)\n",
        "        # 1. Selection from the table (Embedding)\n",
        "        x = self.embedding(x) # Output: [Batch, Seq, d_model]\n",
        "\n",
        "        # 2. Addition of position (PE)\n",
        "        x = self.pos_encoding(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "        assert d_model % num_heads == 0\n",
        "\n",
        "        self.d_k = d_model // num_heads # Dimension of each head\n",
        "\n",
        "        # Defining 4 linear layers\n",
        "        self.w_q = nn.Linear(d_model, d_model)\n",
        "        self.w_k = nn.Linear(d_model, d_model)\n",
        "        self.w_v = nn.Linear(d_model, d_model)\n",
        "        self.w_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        batch_size = q.size(0)\n",
        "\n",
        "        # 1. Linear projections and split into heads\n",
        "        # View as: [Batch, Seq, Heads, d_k] -> Transpose to: [Batch, Heads, Seq, d_k]\n",
        "        q = self.w_q(q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        k = self.w_k(k).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        v = self.w_v(v).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "        # 2. Scaled Dot-Product Attention\n",
        "        # scores = (Q * K^T) / sqrt(d_k)\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        attn = torch.softmax(scores, dim=-1)\n",
        "\n",
        "        # 3. Multiply by V and Concatenate\n",
        "        # context = (Attn * V)\n",
        "        context = torch.matmul(attn, v) # [Batch, Heads, Seq, d_k]\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
        "\n",
        "        # 4. Final output projection (W_o)\n",
        "        return self.w_o(context)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super(FeedForward, self).__init__()\n",
        "        # 1st layer expands the dimension\n",
        "        self.w_1 = nn.Linear(d_model, d_ff)\n",
        "        # 2nd layer brings it back to d_model\n",
        "        self.w_2 = nn.Linear(d_ff, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply Linear -> ReLU -> Dropout -> Linear\n",
        "        return self.w_2(self.dropout(torch.relu(self.w_1(x))))\n",
        "\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super(EncoderBlock, self).__init__()\n",
        "        self.attention = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = FeedForward(d_model, d_ff, dropout)\n",
        "\n",
        "        # Two normalization layers for the two \"floors\" of the block\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # --- Floor 1: Multi-Head Attention ---\n",
        "        # 1. Calculate attention (Self-Attention)\n",
        "        attn_output = self.attention(x, x, x, mask)\n",
        "\n",
        "        # 2. Add & Norm (Residual Connection)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "\n",
        "        # --- Floor 2: Feed Forward ---\n",
        "        # 3. Apply Feed Forward\n",
        "        ff_output = self.feed_forward(x)\n",
        "\n",
        "        # 4. Add & Norm (Residual Connection)\n",
        "        x = self.norm2(x + self.dropout(ff_output))\n",
        "\n",
        "        return x\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, dropout=0.1):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        # Input layer from Step A (Embedding + Positional Encoding)\n",
        "        self.input_layer = TransformerInput(vocab_size, d_model)\n",
        "\n",
        "        # Creating a stack of encoder blocks\n",
        "        self.layers = nn.ModuleList([\n",
        "            EncoderBlock(d_model, num_heads, d_ff, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # 1. Convert indices to vectors with position\n",
        "        x = self.input_layer(x)\n",
        "\n",
        "        # 2. Pass through each encoder block in the stack\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "\n",
        "        return self.norm(x)\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "    mask = torch.tril(torch.ones(size, size)).type(torch.uint8)\n",
        "    return mask.unsqueeze(0) # Add batch dimension\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        # 1. Self Attention (looking at the answer so far)\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        # 2. Cross Attention (looking at the encoder's output)\n",
        "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.feed_forward = FeedForward(d_model, d_ff, dropout)\n",
        "\n",
        "        # We need 3 normalization layers now\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask=None, tgt_mask=None):\n",
        "        \"\"\"\n",
        "        x: target sequence (the answer being generated)\n",
        "        enc_output: the memory/output from the encoder\n",
        "        src_mask: mask for the encoder (padding)\n",
        "        tgt_mask: mask for the decoder (look-ahead + padding)\n",
        "        \"\"\"\n",
        "\n",
        "        # --- Floor 1: Masked Self-Attention ---\n",
        "        # Query, Key, Value all come from x\n",
        "        attn1 = self.self_attn(x, x, x, tgt_mask)\n",
        "        x = self.norm1(x + self.dropout(attn1))\n",
        "\n",
        "        # --- Floor 2: Cross-Attention (The Connection!) ---\n",
        "        # Query comes from the current decoder state (x)\n",
        "        # Key and Value come from the Encoder (enc_output)\n",
        "        attn2 = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
        "        x = self.norm2(x + self.dropout(attn2))\n",
        "\n",
        "        # --- Floor 3: Feed Forward ---\n",
        "        x = self.norm3(x + self.dropout(self.feed_forward(x)))\n",
        "\n",
        "        return x\n",
        "\n",
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, dropout=0.1):\n",
        "        super(TransformerDecoder, self).__init__()\n",
        "        self.input_layer = TransformerInput(vocab_size, d_model)\n",
        "        self.layers = nn.ModuleList([\n",
        "            DecoderBlock(d_model, num_heads, d_ff, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask=None, tgt_mask=None):\n",
        "        x = self.input_layer(x)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, enc_output, src_mask, tgt_mask)\n",
        "        return self.norm(x)\n",
        "\n",
        "def make_masks(src, tgt, pad_idx):\n",
        "    # 1. Source Mask: Tells the encoder to ignore padding in the question\n",
        "    src_mask = (src != pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "    # 2. Target Mask: Combined Padding Mask + Look-ahead Mask\n",
        "    tgt_pad_mask = (tgt != pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "    tgt_len = tgt.size(1)\n",
        "    look_ahead_mask = torch.tril(torch.ones(tgt_len, tgt_len)).type(torch.uint8).to(src.device)\n",
        "\n",
        "    tgt_mask = tgt_pad_mask & look_ahead_mask.bool()\n",
        "\n",
        "    return src_mask, tgt_mask\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_layers, num_heads, d_ff, dropout=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        # The two main parts we already built\n",
        "        self.encoder = TransformerEncoder(src_vocab_size, d_model, num_layers, num_heads, d_ff, dropout)\n",
        "        self.decoder = TransformerDecoder(tgt_vocab_size, d_model, num_layers, num_heads, d_ff, dropout)\n",
        "\n",
        "        # Final Linear layer to project back to vocabulary size\n",
        "        self.generator = nn.Linear(d_model, tgt_vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n",
        "        # 1. Encode the source (question)\n",
        "        enc_output = self.encoder(src, src_mask)\n",
        "\n",
        "        # 2. Decode using encoder's memory\n",
        "        dec_output = self.decoder(tgt, enc_output, src_mask, tgt_mask)\n",
        "\n",
        "        # 3. Project to vocabulary probabilities\n",
        "        return self.generator(dec_output)"
      ],
      "metadata": {
        "id": "fvF9UYr90qf2"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_table = CharacterTable(chars)\n",
        "pad_idx = char_table.char_indices[' ']\n",
        "\n",
        "# 1. Configuration - adjust based on your character set\n",
        "# If your chars are \"0123456789+ \", then vocab size is 12\n",
        "src_vocab_size = len(char_table.chars)\n",
        "tgt_vocab_size = len(char_table.chars)\n",
        "\n",
        "# Hyperparameters\n",
        "d_model = 128\n",
        "num_layers = 4      # Number of Encoder and Decoder blocks\n",
        "num_heads = 8       # d_model must be divisible by num_heads (128/8 = 16)\n",
        "d_ff = 512          # Dimension of the Feed Forward layer (usually 4x d_model)\n",
        "dropout = 0.1\n",
        "\n",
        "# 2. Instantiate the model\n",
        "model = Transformer(\n",
        "    src_vocab_size,\n",
        "    tgt_vocab_size,\n",
        "    d_model,\n",
        "    num_layers,\n",
        "    num_heads,\n",
        "    d_ff,\n",
        "    dropout\n",
        ")\n",
        "\n",
        "# 3. Move to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
      ],
      "metadata": {
        "id": "VbYeP_BthmoN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --- 1. Constants and Config (Exactly as requested) ---\n",
        "config = {\n",
        "    \"training_size\": 40000,\n",
        "    \"digits\": 4,\n",
        "    \"hidden_size\": 128,\n",
        "    \"batch_size\": 128,\n",
        "    \"iterations\": 50\n",
        "}\n",
        "chars = '0123456789-+ '\n",
        "ctable = CharacterTable(chars)\n",
        "\n",
        "# Question length: digits + operator + digits (e.g., 4+1+4 = 9)\n",
        "maxlen_q = config['digits'] + 1 + config['digits']\n",
        "# Answer length: digits + 1 (for sign) + 1 (for SOS space)\n",
        "maxlen_a = config['digits'] + 2\n",
        "\n",
        "questions = []\n",
        "expected = []\n",
        "seen = set()\n",
        "\n",
        "# --- 2. Data Generation Loop ---\n",
        "print('Generating data...')\n",
        "while len(questions) < config[\"training_size\"]:\n",
        "    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
        "                    for i in range(np.random.randint(1, config['digits'] + 1))))\n",
        "    a, b = f(), f()\n",
        "\n",
        "    # Ensuring unique questions (sorting keys for commutativity check if needed)\n",
        "    key = tuple(sorted((a, b)))\n",
        "    if key in seen:\n",
        "        continue\n",
        "    seen.add(key)\n",
        "\n",
        "    # Pad the question with spaces\n",
        "    q = '{}-{}'.format(a, b)\n",
        "    query = q + ' ' * (maxlen_q - len(q))\n",
        "\n",
        "    # Prepend a space as SOS (Start of Sentence) and pad the answer\n",
        "    ans = ' ' + str(a - b)\n",
        "    ans += ' ' * (maxlen_a - len(ans))\n",
        "\n",
        "    questions.append(query)\n",
        "    expected.append(ans)\n",
        "\n",
        "print(f'Total questions generated: {len(questions)}')\n",
        "\n",
        "# --- 3. Vectorization (Mapping to Indices, NOT One-Hot) ---\n",
        "# Shape: [Total_Samples, Seq_Length]\n",
        "x = np.zeros((len(questions), maxlen_q), dtype=np.int64)\n",
        "y = np.zeros((len(expected), maxlen_a), dtype=np.int64)\n",
        "\n",
        "for i, sentence in enumerate(questions):\n",
        "    x[i] = [ctable.char_indices[char] for char in sentence]\n",
        "\n",
        "for i, sentence in enumerate(expected):\n",
        "    y[i] = [ctable.char_indices[char] for char in sentence]\n",
        "\n",
        "# --- 4. Shuffle and Split ---\n",
        "indices = np.arange(len(y))\n",
        "np.random.shuffle(indices)\n",
        "x = x[indices]\n",
        "y = y[indices]\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# --- 5. PyTorch Tensors and DataLoaders ---\n",
        "# We use LongTensor because Embedding layers expect integers\n",
        "x_train_tensor = torch.LongTensor(x_train)\n",
        "y_train_tensor = torch.LongTensor(y_train)\n",
        "\n",
        "x_val_tensor = torch.LongTensor(x_val)\n",
        "y_val_tensor = torch.LongTensor(y_val)\n",
        "\n",
        "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
        "\n",
        "print(f'Training size: {len(x_train)}, Validation size: {len(x_val)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afkPHpZCjE5g",
        "outputId": "0aea92d9-7eac-4ed6-c085-caf8ec4b9dbc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating data...\n",
            "Total questions generated: 40000\n",
            "Training size: 36000, Validation size: 4000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = config['iterations']\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        src, tgt = batch[0].to(device), batch[1].to(device)\n",
        "\n",
        "        # Teacher Forcing: Prepare inputs and labels\n",
        "        tgt_input = tgt[:, :-1]\n",
        "        tgt_labels = tgt[:, 1:]\n",
        "\n",
        "        src_mask, tgt_mask = make_masks(src, tgt_input, pad_idx)\n",
        "\n",
        "        preds = model(src, tgt_input, src_mask, tgt_mask)\n",
        "\n",
        "        loss = criterion(\n",
        "            preds.view(-1, preds.size(-1)),\n",
        "            tgt_labels.contiguous().view(-1)\n",
        "        )\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # --- Validation Phase ---\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        model.eval()\n",
        "        char_acc, total_chars, seq_acc, total_samples = 0, 0, 0, 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                src, tgt = batch[0].to(device), batch[1].to(device)\n",
        "                tgt_input = tgt[:, :-1]\n",
        "                tgt_labels = tgt[:, 1:]\n",
        "\n",
        "                src_mask, tgt_mask = make_masks(src, tgt_input, pad_idx)\n",
        "                preds = model(src, tgt_input, src_mask, tgt_mask)\n",
        "                pred_indices = preds.argmax(dim=-1)\n",
        "\n",
        "                # Metrics logic\n",
        "                mask = (tgt_labels != pad_idx)\n",
        "                correct_chars = (pred_indices == tgt_labels) & mask\n",
        "                char_acc += correct_chars.sum().item()\n",
        "                total_chars += mask.sum().item()\n",
        "\n",
        "                seq_matches = (pred_indices == tgt_labels).all(dim=1)\n",
        "                seq_acc += seq_matches.sum().item()\n",
        "                total_samples += src.size(0)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}\")\n",
        "        print(f\"Character Accuracy: {char_acc / total_chars:.4f}\")\n",
        "        print(f\"Full Equation Accuracy: {seq_acc / total_samples:.4f}\")\n",
        "\n",
        "# --- Display 5 Examples ---\n",
        "print(\"-\" * 30)\n",
        "for i in range(5):\n",
        "    idx = random.randint(0, src.size(0) - 1)\n",
        "\n",
        "    q = ctable.decode(src[idx].cpu().numpy())\n",
        "    expected = ctable.decode(tgt_labels[idx].cpu().numpy())\n",
        "    predicted = ctable.decode(pred_indices[idx].cpu().numpy())\n",
        "\n",
        "    print(f\"Q: {q} | Expected: {expected} | Predicted: {predicted}\")\n",
        "    print(\"-\" * 30 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnfNOPESgYy3",
        "outputId": "2c183878-1ad1-4ddc-b1f2-a5482a349c48"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/50, Loss: 0.9437\n",
            "Character Accuracy: 0.5644\n",
            "Full Equation Accuracy: 0.0808\n",
            "Epoch 10/50, Loss: 0.7723\n",
            "Character Accuracy: 0.6372\n",
            "Full Equation Accuracy: 0.2052\n",
            "Epoch 15/50, Loss: 0.6770\n",
            "Character Accuracy: 0.6964\n",
            "Full Equation Accuracy: 0.3033\n",
            "Epoch 20/50, Loss: 0.5835\n",
            "Character Accuracy: 0.7427\n",
            "Full Equation Accuracy: 0.3815\n",
            "Epoch 25/50, Loss: 0.4403\n",
            "Character Accuracy: 0.8157\n",
            "Full Equation Accuracy: 0.5450\n",
            "Epoch 30/50, Loss: 0.2631\n",
            "Character Accuracy: 0.9186\n",
            "Full Equation Accuracy: 0.7688\n",
            "Epoch 35/50, Loss: 0.1196\n",
            "Character Accuracy: 0.9705\n",
            "Full Equation Accuracy: 0.8995\n",
            "Epoch 40/50, Loss: 0.0533\n",
            "Character Accuracy: 0.9914\n",
            "Full Equation Accuracy: 0.9683\n",
            "Epoch 45/50, Loss: 0.0274\n",
            "Character Accuracy: 0.9975\n",
            "Full Equation Accuracy: 0.9878\n",
            "Epoch 50/50, Loss: 0.0161\n",
            "Character Accuracy: 0.9988\n",
            "Full Equation Accuracy: 0.9955\n",
            "------------------------------\n",
            "Q: 0-60      | Expected: -60   | Predicted: -60  \n",
            "------------------------------\n",
            "\n",
            "Q: 663-4     | Expected: 659   | Predicted: 659  \n",
            "------------------------------\n",
            "\n",
            "Q: 68-78     | Expected: -10   | Predicted: -10  \n",
            "------------------------------\n",
            "\n",
            "Q: 47-693    | Expected: -646  | Predicted: -646 \n",
            "------------------------------\n",
            "\n",
            "Q: 117-962   | Expected: -845  | Predicted: -845 \n",
            "------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-d0eIM6FeaM"
      },
      "source": [
        "## Part 2: A language translation model with attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80jhFbWPMW_a"
      },
      "source": [
        "In this part of the problem set we are going to implement a translation with a Sequence to Sequence Network and Attention model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0."
      ],
      "metadata": {
        "id": "Xva-xocThFk6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgL38lJGTYaF"
      },
      "source": [
        "0) Please go over the NLP From Scratch: Translation with a Sequence to Sequence Network and Attention [tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html). This attention model is very similar to what was learned in class (Luong), but a bit different. What are the main differences between  Badahnau and Luong attention mechanisms?    \n",
        "\n",
        "0. Bahdanau attention calculates the scores using the previous decoder state before generating the current word, whereas Luong attention uses the current decoder state. Mathematically, Bahdanau uses an additive function (a small neural network) to find the weights, while Luong typically uses a faster multiplicative (dot-product) approach.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.a"
      ],
      "metadata": {
        "id": "266WnnELhAuS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.a) Using `!wget`, `!unzip` , download and extract the [hebrew-english](https://www.manythings.org/anki/) sentence pairs text file to the Colab `content/`  folder (or local folder if not using Colab).\n",
        "1.b) The `heb.txt` must be parsed and cleaned (see tutorial for requirements or change the code as you see fit).   \n"
      ],
      "metadata": {
        "id": "KBX873GJlDl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "!wget -q https://www.manythings.org/anki/heb-eng.zip\n",
        "!unzip -o heb-eng.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOogE4YXgO_d",
        "outputId": "812bb6fe-6814-475b-aadd-e1c1619c573d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  heb-eng.zip\n",
            "  inflating: _about.txt              \n",
            "  inflating: heb.txt                 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = s.lower().strip()\n",
        "    # Separate punctuation\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    # Keep English letters, Hebrew letters, and basic punctuation\n",
        "    s = re.sub(r\"[^a-zA-Z\\u0590-\\u05FF.!?]+\", r\" \", s)\n",
        "    return s.strip()\n",
        "\n",
        "\n",
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "    lines = open('heb.txt', encoding='utf-8').read().strip().split('\\n')\n",
        "\n",
        "    # FIX: Slice [0:2] to only get English and Hebrew, ignoring attribution\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')[:2]] for l in lines]\n",
        "\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]\n",
        "\n",
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'heb', True)\n",
        "print(random.choice(pairs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-L5kgzYMcWYN",
        "outputId": "805f0dd0-e1bb-4da4-f527-159e758555a8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 136845 sentence pairs\n",
            "Trimmed to 9221 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "heb 6101\n",
            "eng 3050\n",
            "['   .', 'she is listening to him .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2"
      ],
      "metadata": {
        "id": "_jVJdUeR2crZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.a) Use the tutorial example to build  and train a Hebrew to English translation model with attention (using the parameters in the code cell below). Apply the same `eng_prefixes` filter to limit the train/test data.   \n",
        "2.b) Evaluate your trained model randomly on 20 sentences.  \n",
        "2.c) Show the attention plot for 5 random sentences.  \n"
      ],
      "metadata": {
        "id": "AvIIlNvPlGWB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "c-tVmomvXcKk"
      },
      "outputs": [],
      "source": [
        "# use the following parameters:\n",
        "MAX_LENGTH = 10\n",
        "hidden_size = 128\n",
        "epochs = 50\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded)\n",
        "        return output, hidden\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
        "            decoder_outputs.append(decoder_output)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
        "\n",
        "    def forward_step(self, input, hidden):\n",
        "        output = self.embedding(input)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.out(output)\n",
        "        return output, hidden\n",
        "\n",
        "\n",
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Va = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, query, keys):\n",
        "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "\n",
        "        weights = F.softmax(scores, dim=-1)\n",
        "        context = torch.bmm(weights, keys)\n",
        "\n",
        "        return context, weights\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.attention = BahdanauAttention(hidden_size)\n",
        "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            attentions.append(attn_weights)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, attentions\n",
        "\n",
        "\n",
        "    def forward_step(self, input, hidden, encoder_outputs):\n",
        "        embedded =  self.dropout(self.embedding(input))\n",
        "\n",
        "        query = hidden.permute(1, 0, 2)\n",
        "        context, attn_weights = self.attention(query, encoder_outputs)\n",
        "        input_gru = torch.cat((embedded, context), dim=2)\n",
        "\n",
        "        output, hidden = self.gru(input_gru, hidden)\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "\n",
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n",
        "def get_dataloader(batch_size):\n",
        "    input_lang, output_lang, pairs = prepareData('eng', 'heb', True)\n",
        "\n",
        "    n = len(pairs)\n",
        "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "\n",
        "    for idx, (inp, tgt) in enumerate(pairs):\n",
        "        inp_ids = indexesFromSentence(input_lang, inp)\n",
        "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
        "        inp_ids.append(EOS_token)\n",
        "        tgt_ids.append(EOS_token)\n",
        "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
        "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
        "\n",
        "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
        "                               torch.LongTensor(target_ids).to(device))\n",
        "\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "    return input_lang, output_lang, train_dataloader\n",
        "\n",
        "\n",
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
        "          decoder_optimizer, criterion):\n",
        "\n",
        "    total_loss = 0\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "\n",
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
        "\n",
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "               print_every=100, plot_every=100):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)\n",
        "\n",
        "\n",
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        decoded_words = []\n",
        "        for idx in decoded_ids:\n",
        "            if idx.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            decoded_words.append(output_lang.index2word[idx.item()])\n",
        "    return decoded_words, decoder_attn\n",
        "\n",
        "\n",
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 128\n",
        "batch_size = 32\n",
        "\n",
        "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
        "\n",
        "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "train(train_dataloader, encoder, decoder, epochs, print_every=5, plot_every=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-H1IciXZmQqa",
        "outputId": "12c43ded-fc1a-4d15-a2fa-108f47bd4573"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 136845 sentence pairs\n",
            "Trimmed to 9221 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "heb 6101\n",
            "eng 3050\n",
            "2m 26s (- 21m 59s) (5 10%) 1.6922\n",
            "4m 42s (- 18m 49s) (10 20%) 0.8895\n",
            "6m 55s (- 16m 10s) (15 30%) 0.5189\n",
            "9m 13s (- 13m 49s) (20 40%) 0.2987\n",
            "11m 29s (- 11m 29s) (25 50%) 0.1724\n",
            "13m 47s (- 9m 11s) (30 60%) 0.1076\n",
            "16m 0s (- 6m 51s) (35 70%) 0.0737\n",
            "18m 15s (- 4m 33s) (40 80%) 0.0570\n",
            "20m 31s (- 2m 16s) (45 90%) 0.0462\n",
            "22m 44s (- 0m 0s) (50 100%) 0.0390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "encoder_path = '/content/drive/MyDrive/computational_learning/ps3/encoder.pth'\n",
        "decoder_path = '/content/drive/MyDrive/computational_learning/ps3/attn_decoder.pth'\n",
        "\n",
        "\n",
        "#  -state_dict\n",
        "torch.save(encoder.state_dict(), encoder_path)\n",
        "torch.save(decoder.state_dict(), decoder_path)\n",
        "\n",
        "print(\"Models saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "py9pTXM_vR-B",
        "outputId": "0c7f1539-df5b-49b3-cfa4-4c3daf6804b0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.eval()\n",
        "decoder.eval()\n",
        "evaluateRandomly(encoder, decoder)\n",
        "evaluateRandomly(encoder, decoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTCI9woZnVt7",
        "outputId": "030ff3ee-586a-4b54-b214-79e10e2290a5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">   .\n",
            "= they re all right .\n",
            "< we re fine . <EOS>\n",
            "\n",
            ">       .\n",
            "= i m not even sure who he is .\n",
            "< he is not sure who he is no . <EOS>\n",
            "\n",
            ">   .\n",
            "= they are vegetarians .\n",
            "< he is vegetarians . <EOS>\n",
            "\n",
            ">    .\n",
            "= you re very open .\n",
            "< you re very open . <EOS>\n",
            "\n",
            ">    .\n",
            "= i m waiting for the ferry .\n",
            "< i am waiting for the ferry . <EOS>\n",
            "\n",
            ">     .\n",
            "= i m the one with the car .\n",
            "< i m the one with the car . <EOS>\n",
            "\n",
            ">    .\n",
            "= i m waiting for the ferry .\n",
            "< i am waiting for the ferry . <EOS>\n",
            "\n",
            ">   .\n",
            "= i m afraid .\n",
            "< i m afraid . <EOS>\n",
            "\n",
            ">   !\n",
            "= you re disgusting !\n",
            "< you re disgusting ! <EOS>\n",
            "\n",
            ">      .\n",
            "= you re in better shape than i am .\n",
            "< you re in better shape than i am better .\n",
            "\n",
            ">    .\n",
            "= we re three floors up .\n",
            "< we re three floors up . <EOS>\n",
            "\n",
            ">    .\n",
            "= i m not really nervous .\n",
            "< i m really not arguing . <EOS>\n",
            "\n",
            ">     .\n",
            "= i m a us citizen .\n",
            "< i m a us citizen . <EOS>\n",
            "\n",
            ">    .\n",
            "= you re unreal .\n",
            "< you re unreal . <EOS>\n",
            "\n",
            ">     .\n",
            "= we re not to be disturbed .\n",
            "< we re not to be disturbed . <EOS>\n",
            "\n",
            ">     .\n",
            "= she s smartly dressed .\n",
            "< she s smartly dressed . <EOS>\n",
            "\n",
            ">    .\n",
            "= she is being quiet for the moment .\n",
            "< she is being quiet for the moment . <EOS>\n",
            "\n",
            ">   .\n",
            "= i m back from vacation .\n",
            "< i m back from vacation . <EOS>\n",
            "\n",
            ">    ?\n",
            "= you re crazy aren t you ?\n",
            "< you re crazy aren t leaving are you ? <EOS>\n",
            "\n",
            ">      .\n",
            "= i m in charge of the book department .\n",
            "< we re waiting for the book . <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker"
      ],
      "metadata": {
        "id": "LNeyqg-YxAE8"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!pip install python-bidi arabic-reshaper\n",
        "\n",
        "from bidi.algorithm import get_display\n",
        "import arabic_reshaper\n",
        "\n",
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    fig = plt.figure(figsize=(8, 8))\n",
        "    ax = fig.add_subplot(111)\n",
        "\n",
        "    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    input_tokens = input_sentence.split(' ') + ['<EOS>']\n",
        "    input_tokens = [get_display(arabic_reshaper.reshape(w)) for w in input_tokens]\n",
        "\n",
        "    ax.set_xticks(range(len(input_tokens)))\n",
        "    ax.set_yticks(range(len(output_words)))\n",
        "\n",
        "    ax.set_xticklabels(input_tokens, rotation=90)\n",
        "    ax.set_yticklabels(output_words)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.FixedLocator(range(len(input_tokens))))\n",
        "    ax.yaxis.set_major_locator(ticker.FixedLocator(range(len(output_words))))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "    output_words, attentions = evaluate(encoder, decoder, input_sentence, input_lang, output_lang)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    showAttention(input_sentence, output_words, attentions[0, :len(output_words), :])\n",
        "\n",
        "\n",
        "\n",
        "evaluateAndShowAttention('  ')\n",
        "\n",
        "evaluateAndShowAttention('  ')\n",
        "\n",
        "evaluateAndShowAttention('  ')\n",
        "\n",
        "evaluateAndShowAttention('  ')\n",
        "\n",
        "evaluateAndShowAttention(' ')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pU6cOo27nWKR",
        "outputId": "0a7e8111-544a-436d-ad1c-4acba030cd04"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-bidi in /usr/local/lib/python3.12/dist-packages (0.6.7)\n",
            "Requirement already satisfied: arabic-reshaper in /usr/local/lib/python3.12/dist-packages (3.0.0)\n",
            "input =   \n",
            "output = he is a good person . <EOS>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input =   \n",
            "output = she is taller than she looks . <EOS>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input =   \n",
            "output = she is very wise to bed young lady indeed .\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input =   \n",
            "output = i m proud of you . <EOS>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input =  \n",
            "output = i am tired of my daughter . <EOS>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3."
      ],
      "metadata": {
        "id": "Tw-SNLQm2h3C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Do you think this model performs well? Why or why not? What are its limitations/disadvantages? What would you do to improve it?  \n",
        "\n",
        "3. The translations itself are accurat in most cases, However from the observed heatmaps it looks like the model didnt really know what word retales to the word in the translation sentences. In addition the model as it stands limited for only sepecific perfixes and maximum length of sentences.\n",
        "The biggest improvement would be moving from RNNs to Transformers. Transformers use Self-Attention, allowing the model to process all words in a sentence simultaneously rather than one-by-one, which drastically improves translation quality and training speed."
      ],
      "metadata": {
        "id": "qcqtVxkclIWG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4."
      ],
      "metadata": {
        "id": "Lr3bQDlC2j8M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Using any neural network architecture of your liking, build  a model with the aim to beat the model in 2.a. Compare your results in a meaningful way, and add a short explanation to why you think/thought your suggested network is better.\n",
        "\n",
        "4. From the printed example, as a qualitive analysis only I saw that while both models successfully learned to translate Hebrew to English, the Transformer architecture outperformed the Seq2Seq model in terms of translation accuracy. The Seq2Seq model occasionally suffered from hallucinations and struggled with sequence termination. In contrast, the Transformer multi-head attention mechanism provided a more robust understanding of sentence structure."
      ],
      "metadata": {
        "id": "i2VSrRNtlJub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "PAD_token = 2\n",
        "MAX_LENGTH = 10\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=50):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "        self.d_k = d_model // num_heads\n",
        "        self.w_q = nn.Linear(d_model, d_model)\n",
        "        self.w_k = nn.Linear(d_model, d_model)\n",
        "        self.w_v = nn.Linear(d_model, d_model)\n",
        "        self.w_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        batch_size = q.size(0)\n",
        "        q = self.w_q(q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        k = self.w_k(k).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "        v = self.w_v(v).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        attn = torch.softmax(scores, dim=-1)\n",
        "        context = torch.matmul(attn, v).transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
        "        return self.w_o(context)\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_layers, num_heads, d_ff, dropout=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder = TransformerEncoder(src_vocab_size, d_model, num_layers, num_heads, d_ff, dropout)\n",
        "        self.decoder = TransformerDecoder(tgt_vocab_size, d_model, num_layers, num_heads, d_ff, dropout)\n",
        "        self.generator = nn.Linear(d_model, tgt_vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
        "        enc_output = self.encoder(src, src_mask)\n",
        "        dec_output = self.decoder(tgt, enc_output, src_mask, tgt_mask)\n",
        "        return self.generator(dec_output)\n",
        "\n",
        "def make_masks(src, tgt, pad_idx):\n",
        "    src_mask = (src != pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "    tgt_pad_mask = (tgt != pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "    tgt_len = tgt.size(1)\n",
        "    look_ahead_mask = torch.tril(torch.ones(tgt_len, tgt_len)).bool().to(src.device)\n",
        "    tgt_mask = tgt_pad_mask & look_ahead_mask\n",
        "    return src_mask, tgt_mask"
      ],
      "metadata": {
        "id": "_WrHkLD6p813"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = np.full((len(pairs), MAX_LENGTH), PAD_token)\n",
        "target_ids = np.full((len(pairs), MAX_LENGTH), PAD_token)\n",
        "\n",
        "for i, (inp, tgt) in enumerate(pairs):\n",
        "    inp_idx = [input_lang.word2index[w] for w in inp.split(' ')] + [EOS_token]\n",
        "    tgt_idx = [output_lang.word2index[w] for w in tgt.split(' ')] + [EOS_token]\n",
        "    input_ids[i, :len(inp_idx)] = inp_idx[:MAX_LENGTH]\n",
        "    target_ids[i, :len(tgt_idx)] = tgt_idx[:MAX_LENGTH]\n",
        "\n",
        "dataset = TensorDataset(torch.LongTensor(input_ids), torch.LongTensor(target_ids))\n",
        "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "model = Transformer(input_lang.n_words, output_lang.n_words, 128, 4, 8, 512).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_token)\n",
        "\n",
        "model.train()\n",
        "for epoch in range(50):\n",
        "    total_loss = 0\n",
        "    for src, tgt in train_loader:\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "        tgt_input = tgt[:, :-1]\n",
        "        tgt_labels = tgt[:, 1:]\n",
        "\n",
        "        src_mask, tgt_mask = make_masks(src, tgt_input, PAD_token)\n",
        "        preds = model(src, tgt_input, src_mask, tgt_mask)\n",
        "\n",
        "        loss = criterion(preds.reshape(-1, output_lang.n_words), tgt_labels.reshape(-1))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N_2yzdG3iEJ",
        "outputId": "38c7bf6f-8128-4343-e702-022c4aca4c24"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 1.8292\n",
            "Epoch 20, Loss: 0.9594\n",
            "Epoch 30, Loss: 0.4239\n",
            "Epoch 40, Loss: 0.1571\n",
            "Epoch 50, Loss: 0.0686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(model, sentence):\n",
        "    model.eval()\n",
        "    sentence = normalizeString(sentence)\n",
        "    tokens = [input_lang.word2index[w] for w in sentence.split(' ')] + [EOS_token]\n",
        "    src = torch.LongTensor(tokens).unsqueeze(0).to(device)\n",
        "\n",
        "    tgt_indices = [SOS_token]\n",
        "    for _ in range(MAX_LENGTH):\n",
        "        tgt_tensor = torch.LongTensor(tgt_indices).unsqueeze(0).to(device)\n",
        "        src_mask, tgt_mask = make_masks(src, tgt_tensor, PAD_token)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(src, tgt_tensor, src_mask, tgt_mask)\n",
        "\n",
        "        next_word = output[0, -1].argmax().item()\n",
        "        tgt_indices.append(next_word)\n",
        "        if next_word == EOS_token: break\n",
        "\n",
        "    return ' '.join([output_lang.index2word[i] for i in tgt_indices if i not in [SOS_token, EOS_token, PAD_token]])\n",
        "\n",
        "def evaluateRandomlyTransformer(model, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "\n",
        "        output_sentence = translate(model, pair[0])\n",
        "        print('<', output_sentence)\n",
        "        print('')\n",
        "\n",
        "evaluateRandomlyTransformer(model, 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbuzGk9f3qfc",
        "outputId": "957fc01a-e8a8-4882-c06e-38dc49c03340"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">       .\n",
            "= i m not going to take it anymore .\n",
            "< not going to take it anymore .\n",
            "\n",
            ">   .\n",
            "= i m not a painter .\n",
            "< not a painter .\n",
            "\n",
            ">        .\n",
            "= i m sure tom told you that .\n",
            "< tom told you that the it .\n",
            "\n",
            ">   .\n",
            "= i m bald .\n",
            "< .\n",
            "\n",
            ">     .\n",
            "= i am ready to help you .\n",
            "< to help you help you .\n",
            "\n",
            ">     .\n",
            "= you re with friends .\n",
            "< with friends .\n",
            "\n",
            ">     !\n",
            "= you re disgusting !\n",
            "< !\n",
            "\n",
            ">   .\n",
            "= you re forgiven .\n",
            "< to you .\n",
            "\n",
            ">    .\n",
            "= i am going to the shop .\n",
            "< going to the shop .\n",
            "\n",
            ">     .\n",
            "= i m going home now .\n",
            "< going home now .\n",
            "\n",
            ">    .\n",
            "= we re not partners .\n",
            "< not partners .\n",
            "\n",
            ">     .\n",
            "= i m going to the bathroom .\n",
            "< to the bathroom of losing .\n",
            "\n",
            ">     .\n",
            "= i m pleased to see you .\n",
            "< happy to see you .\n",
            "\n",
            ">   .\n",
            "= they re old .\n",
            "< .\n",
            "\n",
            ">      .\n",
            "= i m kind of mad at myself .\n",
            "< mad at kind of myself .\n",
            "\n",
            ">     .\n",
            "= she is lacking in common sense .\n",
            "< to have the problem .\n",
            "\n",
            ">  .\n",
            "= i m wounded .\n",
            "< .\n",
            "\n",
            ">   .\n",
            "= they re students .\n",
            "< .\n",
            "\n",
            ">    .\n",
            "= you re powerful .\n",
            "< to powerful .\n",
            "\n",
            ">     .\n",
            "= i m still mad at her .\n",
            "< still mad at her .\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "transformer_path = '/content/drive/MyDrive/computational_learning/ps3/transformer.pth'\n",
        "\n",
        "torch.save(model.state_dict(), transformer_path)\n",
        "\n",
        "print(f\"The Transformer model was saved successfully to: {transformer_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1Y9Iw_mCLR-",
        "outputId": "f556207d-c647-494d-fef1-0926f0135eef"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Transformer model was saved successfully to: /content/drive/MyDrive/computational_learning/ps3/transformer.pth\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "CiwtNgENbx2g",
        "KC9v9TOPtsIo",
        "94tZgheCwWD1",
        "4l9pQJoswao9",
        "CQd9znvjvdxR",
        "Xva-xocThFk6"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}